{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as m\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbere of outliers removed:  67\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('AASG_Thermed_AllTempsThicksConds.csv',low_memory=False)\n",
    "# Drop 3 sigma outliers for HeatFlow\n",
    "def outlierDrop(df,df_toCheck,std_cut_off):\n",
    "    init_len = df.shape[0]\n",
    "    for i in df_toCheck:\n",
    "        mean = df[i].mean()\n",
    "        std = df[i].std()\n",
    "        cut_off = std * std_cut_off\n",
    "        lower, upper =mean - cut_off, mean + cut_off\n",
    "        df = df[(df[i] < upper) & (df[i] > lower)]\n",
    "    print(\"numbere of outliers removed: \", init_len - df.shape[0])\n",
    "    return df\n",
    "df = outlierDrop(df,['HeatFlow'],3)\n",
    "df = df[df['HeatFlow']>0]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Form X and Y\n",
    "X = np.transpose(np.array([df.LatDegree,\n",
    "                                df.LongDegree,\n",
    "                                df.MeasureDepth_m,\n",
    "                                df.SurfTemp]))\n",
    "Y = df.CorrBHT.values\n",
    "# Add Geological Layer information to X\n",
    "layers = df.iloc[:,52:101].values\n",
    "conds = df.iloc[:,101:150].values\n",
    "mult = np.multiply(layers,conds)\n",
    "np.nan_to_num(mult, 0)\n",
    "X = np.concatenate((X, mult),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "scaled_X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid = Ridge(alpha=0.01)\n",
    "rid.fit(scaled_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model_ridge.sav'\n",
    "pickle.dump(rid, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Keras DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.transpose(np.array([df.LatDegree,\n",
    "                                df.LongDegree,\n",
    "                                df.MeasureDepth_m,\n",
    "                                df.SurfTemp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.CorrBHT.values\n",
    "X_train = np.concatenate((X_train, mult),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20649, 53)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20649, 53)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f50c4a87320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    # Sequential model is for just building up each layer\n",
    "    model = Sequential()\n",
    "    # Kernel initializer sets up the distribution for the random parameters\n",
    "    model.add(Dense(50, #kernel_regularizer=regularizers.l2(0.1),\n",
    "                    kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(50, #kernel_regularizer=regularizers.l2(0.1),\n",
    "                    kernel_initializer='normal', activation='relu'))    \n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasRegressor(build_fn=baseline_model, epochs=150, batch_size=50, verbose=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aryashahdi/venv/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/aryashahdi/venv/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: finalized_model_DNN/assets\n"
     ]
    }
   ],
   "source": [
    "model.model.save(\"finalized_model_DNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
