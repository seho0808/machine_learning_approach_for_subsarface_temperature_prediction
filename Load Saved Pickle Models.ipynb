{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data ( Prepare the test dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "\n",
    "df = pd.read_excel('AASG_Thermed_AllThicksAndConds.xlsx')\n",
    "df2 = pd.read_csv('clean_new_well_data_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbere of outliers removed:  67\n"
     ]
    }
   ],
   "source": [
    "def outlierDrop(df,df_toCheck,std_cut_off):\n",
    "    init_len = df.shape[0]\n",
    "    for i in df_toCheck:\n",
    "        mean = df[i].mean()\n",
    "        std = df[i].std()\n",
    "        cut_off = std * std_cut_off\n",
    "        lower, upper =mean - cut_off, mean + cut_off\n",
    "        df = df[(df[i] < upper) & (df[i] > lower)]\n",
    "    print(\"numbere of outliers removed: \", init_len - df.shape[0])\n",
    "    return df\n",
    "#df = outlierDrop(df,['CorrBHT', 'HeatFlow','MeasureDepth_m'],4)\n",
    "df = outlierDrop(df,['HeatFlow'],3)\n",
    "df = df[df['HeatFlow']>0]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Find Closest Points for Estimation with Phys Model\n",
    "\n",
    "num_sample=10000\n",
    "sampled_df2 = df2.sample(num_sample)\n",
    "\n",
    "import math\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 10.0)) * 10\n",
    "\n",
    "# Round by 10 to later compare with T1~T500\n",
    "sampled_df2.depth = np.round(sampled_df2.depth,decimals=-1).astype('int')\n",
    "\n",
    "sampled_df2\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(np.transpose(np.array([df.LatDegree, df.LongDegree])))\n",
    "pred_indices = neigh.kneighbors(np.transpose(np.array([sampled_df2.lat,sampled_df2.lon])),return_distance=False)\n",
    "\n",
    "sampled_df2.insert(6, 'closest',pred_indices)\n",
    "\n",
    "sampled_df2.reset_index(inplace=True)\n",
    "\n",
    "sampled_df2\n",
    "\n",
    "predicted_values_by_physics_model = []\n",
    "for i in range(0, num_sample):\n",
    "    curr_depth = sampled_df2.depth[i]\n",
    "    curr_row = df.loc[sampled_df2.closest[i]] # obtain the row\n",
    "    t_string = 'T'+str(int(curr_depth/10))\n",
    "    predicted_value = curr_row[t_string]\n",
    "    predicted_values_by_physics_model.append(predicted_value)\n",
    "\n",
    "predicted_values_by_physics_model = np.array(predicted_values_by_physics_model)\n",
    "\n",
    "sampled_df2.insert(8, 'physics_pred', predicted_values_by_physics_model)\n",
    "\n",
    "sampled_df2\n",
    "\n",
    "# Add Geological Information\n",
    "\n",
    "# - Predict: Geological information of sampled_df2, cond1*thick1 + ...\n",
    "\n",
    "lat_to_interpolate = sampled_df2.lat\n",
    "lon_to_interpolate = sampled_df2.lon\n",
    "\n",
    "layers = df.iloc[:,52:101].values\n",
    "conds = df.iloc[:,101:150].values\n",
    "mult = np.multiply(layers,conds)\n",
    "np.nan_to_num(mult, 0)\n",
    "mult.shape\n",
    "\n",
    "# Read optimal values\n",
    "f = open(\"optim_result.out\", \"r\")\n",
    "lines = f.readlines()\n",
    "\n",
    "optimal_neigh = []\n",
    "optimal_width = []\n",
    "for line in lines:\n",
    "    optimal_neigh.append(line.split(',')[0][0])\n",
    "    optimal_width.append(line.split(',')[1])\n",
    "optimal_neigh = np.array(optimal_neigh).astype('int')\n",
    "optimal_width = np.array(optimal_width).astype('float')\n",
    "\n",
    "# Predict 49 layers information for each sampled_df2 lat and lon\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "predicted_mults = []\n",
    "for i in range(0,49):\n",
    "    def gaussian_kernel(distances):\n",
    "                kernel_width = optimal_width[i]\n",
    "                weights = np.exp(-(distances**2)/kernel_width)\n",
    "                return weights\n",
    "    knn = KNeighborsRegressor(n_neighbors=optimal_neigh[i],weights=gaussian_kernel)\n",
    "    #knn = KNeighborsRegressor(n_neighbors=1,weights=gaussian_kernel)\n",
    "    knn.fit(np.transpose(np.array([df.LatDegree, df.LongDegree])), mult[:,i])\n",
    "    y_pred = knn.predict(np.transpose(np.array([sampled_df2.lat, sampled_df2.lon])))\n",
    "    predicted_mults.append(y_pred)\n",
    "\n",
    "predicted_mults = np.transpose(np.array(predicted_mults))\n",
    "\n",
    "# Predict T_SURF\n",
    "def gaussian_kernel(distances):\n",
    "            kernel_width = 2.598\n",
    "            weights = np.exp(-(distances**2)/kernel_width)\n",
    "            return weights\n",
    "knn = KNeighborsRegressor(n_neighbors=1,weights=gaussian_kernel)\n",
    "knn.fit(np.transpose(np.array([df.LatDegree, df.LongDegree])), df.SurfTemp)\n",
    "predicted_tsurf = knn.predict(np.transpose(np.array([sampled_df2.lat, sampled_df2.lon])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGB and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load the model from disk\n",
    "gbm = pickle.load(open('xgbSaved.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.transpose(np.array([sampled_df2.lat,\n",
    "                               sampled_df2.lon,\n",
    "                               sampled_df2.depth,\n",
    "                               predicted_tsurf]))\n",
    "X_test = np.concatenate((X_test, predicted_mults),axis=1)\n",
    "y_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.3388  , 29.168438, 30.444153, ..., 63.45916 , 45.91786 ,\n",
       "       26.305988], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
